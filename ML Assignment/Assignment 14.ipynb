{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab92514d",
   "metadata": {},
   "source": [
    "1. What is the concept of supervised learning? What is the significance of the name?\n",
    "\n",
    "Supervised learning uses a training set to teach models to yield the desired output. This training dataset includes inputs and correct outputs, which allow the model to learn over time. The algorithm measures its accuracy through the loss function, adjusting until the error has been sufficiently minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cd3ca7",
   "metadata": {},
   "source": [
    "2. In the hospital sector, offer an example of supervised learning.\n",
    "\n",
    ", a machine learning algorithm can be used in medical imaging (such as X-rays or MRI scans) using pattern recognition to look for patterns that indicate a particular disease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8df44c",
   "metadata": {},
   "source": [
    "3. Give three supervised learning examples.\n",
    "\n",
    "Image and speech recognition, recommendation systems, and fraud detection are all examples of how supervised learning is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb93fca5",
   "metadata": {},
   "source": [
    "4. In supervised learning, what are classification and regression?\n",
    "\n",
    "Regression Algorithms are used with continuous data. Classification Algorithms are used with discrete data. In Regression, we try to find the best fit line, which can predict the output more accurately. In Classification, we try to find the decision boundary, which can divide the dataset into different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5f52e3",
   "metadata": {},
   "source": [
    "5. Give some popular classification algorithms as examples.\n",
    "\n",
    "The K-nearest neighbors algorithm is one of the most basic classification algorithms. It compares each example of a particular class to all examples of that class by proximity. This is useful for two reasons: It's easy to understand and implement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3953e580",
   "metadata": {},
   "source": [
    "6. Briefly describe the SVM model.\n",
    "\n",
    "In machine learning, SVM is used to classify data by finding the optimal decision boundary that maximally separates different classes. It aims to find the best hyperplane that maximizes the margin between support vectors, enabling effective classification even in complex, non-linear scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9eeaa8",
   "metadata": {},
   "source": [
    "7. In SVM, what is the cost of misclassification?\n",
    "\n",
    "Misclassification costs are basically weights applied to specific outcomes. These weights are factored into the model and may actually change the prediction (as a way of protecting against costly mistakes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564a1814",
   "metadata": {},
   "source": [
    "8. In the SVM model, define Support Vectors.\n",
    "\n",
    "Support Vectors: These are the points that are closest to the hyperplane. A separating line will be defined with the help of these data points. Margin: it is the distance between the hyperplane and the observations closest to the hyperplane (support vectors). In SVM large margin is considered a good margin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55b6505",
   "metadata": {},
   "source": [
    "9. In the SVM model, define the kernel.\n",
    "\n",
    "“Kernel” is used due to a set of mathematical functions used in Support Vector Machine providing the window to manipulate the data. So, Kernel Function generally transforms the training set of data so that a non-linear decision surface is able to transform to a linear equation in a higher number of dimension spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5f5284",
   "metadata": {},
   "source": [
    "10. What are the factors that influence SVM&#39;s effectiveness?\n",
    "\n",
    "The effectiveness of SVM depends on the selection of kernel, kernel's parameters and soft margin parameter C. . Each pair of parameters is checked using cross validation, and the parameters with best cross validation accuracy are picked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86374b01",
   "metadata": {},
   "source": [
    "11. What are the benefits of using the SVM model?\n",
    "\n",
    "One of the main advantages of SVM is that it works well in high-dimensional spaces and it's relatively memory efficient. it also able to handle non-linearly separable data by transforming them into a higher dimensional space where they become linear separable, this is done by using kernel trick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5c19b7",
   "metadata": {},
   "source": [
    "12. What are the drawbacks of using the SVM model?\n",
    "\n",
    "SVM algorithm is not suitable for large data sets. SVM does not perform very well when the data set has more noise i.e. target classes are overlapping. In cases where the number of features for each data point exceeds the number of training data samples, the SVM will underperform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c06f949",
   "metadata": {},
   "source": [
    "The kNN algorithm has a validation flaw.\n",
    "\n",
    "Just one drawback with k-fold cross-validation is that we are repeating the computations for each value of K (of KNN). So it basically increases the time complexity.\n",
    "\n",
    "In the kNN algorithm, the k value is chosen.\n",
    "\n",
    "The optimal K value usually found is the square root of N, where N is the total number of samples. Use an error plot or accuracy plot to find the most favorable K value.\n",
    "\n",
    "A decision tree with inductive bias\n",
    "\n",
    "Decision tree learning method searches a completely expressive hypothesis . – Avoids the difficulties of restricted hypothesis spaces. – Its inductive bias is a preference for small trees over large trees. The decision tree algorithms such as ID3, C4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eeadce",
   "metadata": {},
   "source": [
    "What are some of the benefits of the kNN algorithm?\n",
    "\n",
    "The KNN algorithm can compete with the most accurate models because it makes highly accurate predictions. Therefore, you can use the KNN algorithm for applications that require high accuracy but that do not require a human-readable model. The quality of the predictions depends on the distance measure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7681585",
   "metadata": {},
   "source": [
    "15. What are some of the kNN algorithm&#39;s drawbacks?\n",
    "\n",
    "KNN has some drawbacks and challenges, such as computational expense, slow speed, memory and storage issues for large datasets, sensitivity to the choice of k and the distance metric, and susceptibility to the curse of dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c43071e",
   "metadata": {},
   "source": [
    "16. Explain the decision tree algorithm in a few words.\n",
    "\n",
    "A decision tree is a non-parametric supervised learning algorithm, which is utilized for both classification and regression tasks. It has a hierarchical, tree structure, which consists of a root node, branches, internal nodes and leaf nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb31b84d",
   "metadata": {},
   "source": [
    "17. What is the difference between a node and a leaf in a decision tree?\n",
    "\n",
    "In a decision tree, a node represents a decision or a test on a feature, which splits the dataset into two or more subsets based on the values of that feature. A leaf node, on the other hand, represents a decision or prediction, and it does not split the dataset any further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7dfb49",
   "metadata": {},
   "source": [
    "18. What is a decision tree&#39;s entropy?\n",
    "\n",
    "In the context of Decision Trees, entropy is a measure of disorder or impurity in a node. Thus, a node with more variable composition, such as 2Pass and 2 Fail would be considered to have higher Entropy than a node which has only pass or only fail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc34d08a",
   "metadata": {},
   "source": [
    "19. In a decision tree, define knowledge gain.\n",
    "\n",
    "We can use information gain to determine how good the splitting of nodes is in a decision tree. In terms of entropy, information gain is defined as: Gain = (Entropy of the parent node) – (average entropy of the child nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69646eb3",
   "metadata": {},
   "source": [
    "20. Choose three advantages of the decision tree approach and write them down.\n",
    "\n",
    "Advantages \n",
    "\n",
    "1. Relatively Easy to Interpret\n",
    "2. Robust to Outliers\n",
    "3. Can Deal with Missing Values\n",
    "\n",
    "Disadvantages\n",
    "\n",
    "1. Prone to Overfitting\n",
    "2. Unstable to Changes in the Data\n",
    "3. Unstable to Noise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
