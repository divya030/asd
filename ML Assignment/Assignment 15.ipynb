{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77169001",
   "metadata": {},
   "source": [
    "1. Recognize the differences between supervised, semi-supervised, and unsupervised learning.\n",
    "\n",
    "Supervised learning is a problem with labeled data, expecting to develop predictive capability. Unsupervised learning is discovering process, diving into unlabeled data to capture hidden information. Semi-supervised learning is a blend of supervised and unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9846d5bb",
   "metadata": {},
   "source": [
    "2. Describe in detail any five examples of classification problems.\n",
    "\n",
    "Given an example, classify if it is spam or not.\n",
    "\n",
    "Given a handwritten character, classify it as one of the known characters.\n",
    "\n",
    "Given recent user behavior, classify as churn or not.\n",
    "\n",
    "Email spam detection (spam or not).\n",
    "\n",
    "Churn prediction (churn or not).\n",
    "\n",
    "Conversion prediction (buy or not)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57219c6f",
   "metadata": {},
   "source": [
    "3. Describe each phase of the classification process in detail.\n",
    "\n",
    "1. Collect the data\n",
    "The first step of data classification often overlaps with the data aggregation phase of a typical data lifecycle management framework. At this step of the data classification process, users collect raw data based on attributes and parameters that may be useful for classification at a later stage.\n",
    "\n",
    "2. Define classification levels\n",
    "Organizations outline the business, technical, security, compliance and privacy objectives and how these apply to their data assets. \n",
    "\n",
    "3. Categorize the data\n",
    "This phase focuses on defining patterns and criteria which allow users to classify data assets. Data owners, in collaboration with IT and security teams, assess the content, context and potential impact of each data asset to determine its appropriate classification level. The categorization process may involve the following:\n",
    "\n",
    "Interviews\n",
    "Documentation reviews\n",
    "Automated scanning tools \n",
    "Classification workflows\n",
    "\n",
    "4. Apply security controls and appropriate monitoring\n",
    "Once the data assets are classified, appropriate security controls and protection mechanisms are applied based on the assigned classification level. Levels generally include:\n",
    "\n",
    "Low sensitivity data assets, such as press releases and public-facing content, may not require additional security measures\n",
    "Medium sensitivity level classification outcomes such as IT network performance may require some security measures as they can expose the network to potential security risk\n",
    "Highly sensitive data may include confidential information, IP-protected insights, financial and personally identifiable information\n",
    "\n",
    "5. Review, updates and training\n",
    "Data classification is an ongoing process that requires regular review and updates. As data evolves, new data assets are created and existing data may change in sensitivity. The organization should conduct periodic reviews of data classifications to ensure their accuracy and relevance, making adjustments as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b29014",
   "metadata": {},
   "source": [
    "4. Go through the SVM model in depth using various scenarios.\n",
    "\n",
    "A support vector machine (SVM) is a type of supervised learning algorithm used in machine learning to solve classification and regression tasks; SVMs are particularly good at solving binary classification problems, which require classifying the elements of a data set into two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8fa610",
   "metadata": {},
   "source": [
    "5. What are some of the benefits and drawbacks of SVM?\n",
    "\n",
    "Advantages of Support Vector Machine:\n",
    "\n",
    "SVM works relatively well when there is a clear margin of separation between classes.\n",
    "SVM is more effective in high dimensional spaces.\n",
    "SVM is effective in cases where the number of dimensions is greater than the number of samples.\n",
    "SVM is relatively memory efficient\n",
    "\n",
    "Disadvantages of Support Vector Machine:\n",
    "\n",
    "SVM algorithm is not suitable for large data sets.\n",
    "SVM does not perform very well when the data set has more noise i.e. target classes are overlapping.\n",
    "In cases where the number of features for each data point exceeds the number of training data samples, the SVM will underperform.\n",
    "As the support vector classifier works by putting data points, above and below the classifying hyperplane there is no probabilistic explanation for the classification.m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2549ce36",
   "metadata": {},
   "source": [
    "6. Go over the kNN model in depth.\n",
    "\n",
    "The K-Nearest Neighbor (KNN) algorithm is a popular machine learning technique used for classification and regression tasks. It relies on the idea that similar data points tend to have similar labels or values. During the training phase, the KNN algorithm stores the entire training dataset as a reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff964f6",
   "metadata": {},
   "source": [
    "7. Discuss the kNN algorithm&#39;s error rate and validation error.\n",
    "\n",
    "error rate initially decreases and reaches a minima. After the minima point, it then increase with increasing K. To get the optimal value of K, you can segregate the training and validation from the initial dataset. Now plot the validation error curve to get the optimal value of K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c73a91",
   "metadata": {},
   "source": [
    "9. Create the kNN algorithm.\n",
    "\n",
    "Calculate the distance between test data and each row of training dataset.\n",
    "\n",
    "Sort the calculated distances in ascending order based on distance values.\n",
    "\n",
    "Get top k rows from the sorted array.\n",
    "\n",
    "Get the most frequent class of these rows.\n",
    "\n",
    "Return the predicted class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0f0be5",
   "metadata": {},
   "source": [
    "What is a decision tree, exactly? What are the various kinds of nodes? Explain all in depth.\n",
    "\n",
    "A decision tree is a non-parametric supervised learning algorithm for classification and regression tasks. It has a hierarchical tree structure consisting of a root node, branches, internal nodes, and leaf nodes. Decision trees are used for classification and regression tasks, providing easy-to-understand models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00b597",
   "metadata": {},
   "source": [
    "11. Describe the different ways to scan a decision tree.\n",
    "\n",
    "Define your main idea or question.\n",
    "\n",
    "Add potential decisions and outcomes.\n",
    "\n",
    "Expand until you hit end points.\n",
    "\n",
    "Calculate risk and reward.\n",
    "\n",
    "Evaluate outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71de88d8",
   "metadata": {},
   "source": [
    "12. Describe in depth the decision tree algorithm.\n",
    "\n",
    "This algorithm compares the values of root attribute with the record (real dataset) attribute and, based on the comparison, follows the branch and jumps to the next node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5accf666",
   "metadata": {},
   "source": [
    "13. In a decision tree, what is inductive bias? What would you do to stop overfitting?\n",
    "\n",
    "Post-Pruning or 'backward pruning' is a technique that eliminates branches from a “completely grown” decision tree model to reduce its complexity and variance. This technique allows the decision tree to grow to its full depth, then removes branches to prevent the model from overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d599e20f",
   "metadata": {},
   "source": [
    "14.Explain advantages and disadvantages of using a decision tree?\n",
    "\n",
    "Advantages\n",
    "\n",
    "Compared to other algorithms decision trees requires less effort for data preparation during pre-processing.\n",
    "\n",
    "A decision tree does not require normalization of data.\n",
    "\n",
    "A decision tree does not require scaling of data as well.\n",
    "\n",
    "Missing values in the data also do NOT affect the process of building a decision tree to any considerable extent.\n",
    "\n",
    "A Decision tree model is very intuitive and easy to explain to technical teams as well as stakeholders.\n",
    "\n",
    "Disadvantage:\n",
    "    \n",
    "A small change in the data can cause a large change in the structure of the decision tree causing instability.\n",
    "\n",
    "For a Decision tree sometimes calculation can go far more complex compared to other algorithms.\n",
    "\n",
    "Decision tree often involves higher time to train the model.\n",
    "\n",
    "Decision tree training is relatively expensive as the complexity and time has taken are more.\n",
    "\n",
    "The Decision Tree algorithm is inadequate for applying regression and predicting continuous values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d69a42f",
   "metadata": {},
   "source": [
    "15. Describe in depth the problems that are suitable for decision tree learning.\n",
    "\n",
    "Decision Tree solves the problem of machine learning by transforming the data into a tree representation. Each internal node of the tree representation denotes an attribute and each leaf node denotes a class label. A decision tree algorithm can be used to solve both regression and classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837e6ae5",
   "metadata": {},
   "source": [
    "16. Describe in depth the random forest model. What distinguishes a random forest?\n",
    "\n",
    "Random forests are a way of averaging multiple deep decision trees, trained on different parts of the same training set, with the goal of reducing the variance. This comes at the expense of a small increase in the bias and some loss of interpretability, but generally greatly boosts the performance in the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b017df9c",
   "metadata": {},
   "source": [
    "17. In a random forest, talk about OOB error and variable value.\n",
    "\n",
    "The OOB error is computed using the samples that were not included in the training of the individual trees. This is different from the error computed using the usual training and validation sets, which are used to tune the hyperparameters of the random forest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
