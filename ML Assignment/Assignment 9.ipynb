{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc482692",
   "metadata": {},
   "source": [
    "1. What is feature engineering, and how does it work? Explain the various aspects of feature\n",
    "engineering in depth.\n",
    "\n",
    "Feature engineering is the process of transforming raw data into features that are suitable for machine learning models. In other words, it is the process of selecting, extracting, and transforming the most relevant features from the available data to build more accurate and efficient machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46f3620",
   "metadata": {},
   "source": [
    "2. What is feature selection, and how does it work? What is the aim of it? What are the various\n",
    "methods of function selection?\n",
    "\n",
    "Feature Selection is the method of reducing the input variable to your model by using only relevant data and getting rid of noise in data. It is the process of automatically choosing relevant features for your machine learning model based on the type of problem you are trying to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1346f4f",
   "metadata": {},
   "source": [
    "3. Describe the function selection filter and wrapper approaches. State the pros and cons of each\n",
    "approach?\n",
    "\n",
    "Filter methods measure the relevance of features by their correlation with dependent variable while wrapper methods measure the usefulness of a subset of feature by actually training a model on it. Filter methods are much faster compared to wrapper methods as they do not involve training the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3543728",
   "metadata": {},
   "source": [
    "i. Describe the overall feature selection process.\n",
    "\n",
    "The feature selection process is based on a specific machine learning algorithm we are trying to fit on a given dataset. It follows a greedy search approach by evaluating all the possible combinations of features against the evaluation criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7643400e",
   "metadata": {},
   "source": [
    "ii. Explain the key underlying principle of feature extraction using an example. What are the most\n",
    "widely used function extraction algorithms?\n",
    "\n",
    "Feature extraction refers to the process of transforming raw data into numerical features that can be processed while preserving the information in the original data set. It yields better results than applying machine learning directly to the raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6ef000",
   "metadata": {},
   "source": [
    "5. Describe the feature engineering process in the sense of a text categorization issue.\n",
    "\n",
    "The most important part of text classification is feature engineering: the process of creating features for a machine learning model from raw text data. In this article, I will explain different methods to analyze text and extract features that can be used to build a classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d272c8e6",
   "metadata": {},
   "source": [
    "6. What makes cosine similarity a good metric for text categorization? A document-term matrix has\n",
    "two rows with values of (2, 3, 2, 0, 2, 3, 3, 0, 1) and (2, 1, 0, 0, 3, 2, 1, 3, 1). Find the resemblance in\n",
    "cosine.\n",
    "\n",
    "The cosine similarity is beneficial because even if the two similar data objects are far apart by the Euclidean distance because of the size, they could still have a smaller angle between them. Smaller the angle, higher the similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9cc01a",
   "metadata": {},
   "source": [
    "i. What is the formula for calculating Hamming distance? Between 10001011 and 11001111,\n",
    "calculate the Hamming gap.\n",
    "\n",
    "given the two codewords 10001001 and 10110001, their Hamming distance is 3, as the bit positions colored blue differ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769e80c4",
   "metadata": {},
   "source": [
    "ii. Compare the Jaccard index and similarity matching coefficient of two features with values (1, 1, 0,\n",
    "0, 1, 0, 1, 1) and (1, 1, 0, 0, 0, 1, 1, 1), respectively (1, 0, 0, 1, 1, 0, 0, 1).\n",
    "\n",
    "Jaccard's coefficient is different from the matching coefficient in that the former: does not count matching zero entries while the latter does. Single linkage measures dissimilarity between two clusters by considering: only the two closest observations in these clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dbbd17",
   "metadata": {},
   "source": [
    "Use of vectors\n",
    "\n",
    "vectors are used to represent displacement, velocity, and acceleration. Vectors are a combination of magnitude and direction and are drawn as arrows. The length represents the magnitude and the direction of that quantity is the direction in which the vector is pointing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1901b404",
   "metadata": {},
   "source": [
    "Embedded technique\n",
    "\n",
    "Embedded methods combine the qualities' of filter and wrapper methods. It's implemented by algorithms that have their own built-in feature selection methods. Some of the most popular examples of these methods are LASSO and RIDGE regression which have inbuilt penalization functions to reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c805481",
   "metadata": {},
   "source": [
    "Sequential backward exclusion vs. sequential forward selection\n",
    "\n",
    "This Sequential Feature Selector adds (forward selection) or removes (backward selection) features to form a feature subset in a greedy fashion. At each stage, this estimator chooses the best feature to add or remove based on the cross-validation score of an estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3424b6",
   "metadata": {},
   "source": [
    "Function selection methods: filter vs. wrapper\n",
    "    \n",
    "The main differences between the filter and wrapper methods for feature selection are: Filter methods measure the relevance of features by their correlation with dependent variable while wrapper methods measure the usefulness of a subset of feature by actually training a model on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4272f8b",
   "metadata": {},
   "source": [
    "SMC vs. Jaccard coefficient\n",
    "\n",
    "the SMC counts both mutual presences (when an attribute is present in both sets) and mutual absence (when an attribute is absent in both sets) as matches and compares it to the total number of attributes in the universe, whereas the Jaccard index only counts mutual presence as matches and compares it to the number of attributes that have been chosen by at least one of the two sets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
